code 1 :
import os
import re
import logging
import pymysql
import traceback
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta
import json
import sqlparse
from langchain_community.utilities import SQLDatabase
from langchain_ollama import OllamaLLM
from langchain.chains import create_sql_query_chain
import hashlib
from collections import defaultdict

# --- TEAM DETAILS CONFIGURATION ---
TEAM_DB_CONFIG = {
    "name": "Team Details",
    "db_config": {
        "host": "localhost",
        "user": "root",
        "password": "root123",
        "database": "EIS_n"
    },
    "include_tables": ["UserMaster"],
}

# Context-aware configuration
CONTEXT_CONFIG = {
    "max_history_items": 10,  # Maximum conversation history to maintain
    "context_expiry_minutes": 30,  # Context expires after 30 minutes
    "similarity_threshold": 0.7,  # Threshold for context relevance
    "cache_size": 100,  # Maximum cached queries
}

# Blocked patterns for security
BLOCKED_PATTERNS = [
    r"\brm\b", r"\bkill\b", r"\breboot\b", r"\bshutdown\b", r"\buserdel\b",
    r"\bpasswd\b", r"\bmkfs\b", r"\bwget\b", r"\bcurl\b", r":\s*(){:|:&};:",
    r"\bsudo\b", r"\bsu\b", r"\bchmod\b", r"\bchown\b", r"\bdd\b",
    r"\bmount\s+/", r"\bumount\b", r"\bfdisk\b", r"\bparted\b", r"\bmkfs\b",
    r"\biptables\b", r"\bufw\b", r"\bfirewall\b", r"\bselinux\b"
]

# Sensitive fields that should never be included in queries or results
SENSITIVE_FIELDS = ["Pwd", "SecQ", "SecA"]

# Field mappings for better query understanding
FIELD_MAPPINGS = {
    "phone": "Contact",
    "mobile": "Contact",
    "contact": "Contact",
    "phone_number": "Contact",
    "employee_id": "Uid",
    "emp_id": "Uid",
    "id": "Uid",
    "name": "EmpName",
    "employee_name": "EmpName",
    "emp_name": "EmpName",
    "email": "TcsEmail",
    "tcs_email": "TcsEmail",
    "sbi_email": "SbiEmail",
    "ad_id": "AdId",
    "position": "Position",
    "level": "Level",
    "team": "Team",
    "project": "Project",
    "information":"EmpName and Uid",
}

# Context keywords that indicate when to use conversation history
CONTEXT_KEYWORDS = [
    "also", "too", "same", "similar", "like that", "those", "these",
    "him", "her", "them", "their", "his", "hers", "that person",
    "previous", "before", "earlier", "last", "recent", "again",
    "more", "other", "another", "additional", "and", "plus",
    "what about", "how about", "tell me about"
]

# Non-context keywords that indicate a fresh query
FRESH_QUERY_KEYWORDS = [
    "new", "different", "instead", "change", "switch", "forget",
    "ignore", "clear", "reset", "start over", "begin"
]

# Setup logging
logging.basicConfig(
    filename=os.path.expanduser("~/.team_details_ai.log"),
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class QueryCache:
    """Simple query cache to improve response time"""
    def __init__(self, max_size: int = 100):
        self.cache = {}
        self.access_times = {}
        self.max_size = max_size

    def _generate_key(self, query: str) -> str:
        """Generate cache key from query"""
        return hashlib.md5(query.lower().strip().encode()).hexdigest()

    def get(self, query: str) -> Optional[str]:
        """Get cached result if exists and not expired"""
        key = self._generate_key(query)
        if key in self.cache:
            # Check if cache entry is still valid (within 5 minutes)
            if datetime.now() - self.access_times[key] < timedelta(minutes=5):
                self.access_times[key] = datetime.now()  # Update access time
                logger.info(f"Cache hit for query: {query[:50]}...")
                return self.cache[key]
            else:
                # Remove expired entry
                del self.cache[key]
                del self.access_times[key]
        return None

    def set(self, query: str, result: str):
        """Cache query result"""
        key = self._generate_key(query)

        # Remove oldest entries if cache is full
        if len(self.cache) >= self.max_size:
            oldest_key = min(self.access_times.keys(), key=lambda k: self.access_times[k])
            del self.cache[oldest_key]
            del self.access_times[oldest_key]

        self.cache[key] = result
        self.access_times[key] = datetime.now()
        logger.info(f"Cached result for query: {query[:50]}...")

class ConversationContext:
    """Manages conversation context and history"""
    def __init__(self, max_items: int = 10, expiry_minutes: int = 30):
        self.history = []
        self.max_items = max_items
        self.expiry_minutes = expiry_minutes
        self.last_query_entities = {}  # Store entities from last query
        self.session_start = datetime.now()

    def add_interaction(self, question: str, response: str, entities: Dict = None):
        """Add interaction to conversation history"""
        interaction = {
            'timestamp': datetime.now(),
            'question': question.strip(),
            'response': response,
            'entities': entities or {}
        }

        self.history.append(interaction)

        # Maintain max size
        if len(self.history) > self.max_items:
            self.history.pop(0)

        # Update last query entities
        if entities:
            self.last_query_entities.update(entities)

    def should_use_context(self, question: str) -> bool:
        """Determine if context should be applied to current question"""
        question_lower = question.lower().strip()

        # Check for fresh query indicators
        if any(keyword in question_lower for keyword in FRESH_QUERY_KEYWORDS):
            logger.info("Fresh query detected - not using context")
            return False

        # Check for context indicators
        has_context_keywords = any(keyword in question_lower for keyword in CONTEXT_KEYWORDS)

        # Check if question is very short (likely needs context)
        is_short_question = len(question.split()) <= 3

        # Check if question has pronouns or references
        has_pronouns = bool(re.search(r'\b(he|she|it|they|them|him|her|his|hers|their|that|those|these)\b', question_lower))

        # Check if question lacks specific identifiers
        has_specific_ids = bool(re.search(r'\b\d+\b', question)) or any(field in question_lower for field in ['name', 'email', 'team', 'project'])

        should_use = (has_context_keywords or is_short_question or has_pronouns) and len(self.history) > 0

        logger.info(f"Context decision - Keywords: {has_context_keywords}, Short: {is_short_question}, Pronouns: {has_pronouns}, Specific IDs: {has_specific_ids}, Decision: {should_use}")

        return should_use

    def get_relevant_context(self, question: str) -> str:
        """Get relevant context for the current question"""
        if not self.history:
            return ""

        # Get recent interactions (last 3)
        recent_history = self.history[-3:]

        context_parts = []
        context_parts.append("CONVERSATION CONTEXT:")

        for i, interaction in enumerate(recent_history, 1):
            context_parts.append(f"Previous Q{i}: {interaction['question']}")

            # Include entities from previous queries
            if interaction['entities']:
                entities_str = ", ".join([f"{k}: {v}" for k, v in interaction['entities'].items()])
                context_parts.append(f"Previous entities: {entities_str}")

        context_parts.append("CURRENT QUESTION:")
        context_parts.append(question)
        context_parts.append("\nUse the context above to understand references like 'he', 'she', 'them', 'that person', 'same team', etc.")

        return "\n".join(context_parts)

    def extract_entities(self, question: str, sql_result: List[Dict]) -> Dict:
        """Extract entities from question and results for future context"""
        entities = {}

        # Extract employee IDs from question
        uid_matches = re.findall(r'\b(\d+)\b', question)
        if uid_matches:
            entities['employee_ids'] = uid_matches

        # Extract names from question
        name_pattern = r'\b([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\b'
        name_matches = re.findall(name_pattern, question)
        if name_matches:
            entities['names'] = name_matches

        # Extract entities from SQL results
        if sql_result and len(sql_result) <= 5:  # Only for small result sets
            for record in sql_result:
                if 'Uid' in record:
                    entities.setdefault('result_employee_ids', []).append(str(record['Uid']))
                if 'EmpName' in record:
                    entities.setdefault('result_names', []).append(record['EmpName'])
                if 'Team' in record:
                    entities.setdefault('result_teams', []).append(record['Team'])
                if 'Project' in record:
                    entities.setdefault('result_projects', []).append(record['Project'])

        return entities

    def clear_expired_context(self):
        """Remove expired context items"""
        cutoff_time = datetime.now() - timedelta(minutes=self.expiry_minutes)
        self.history = [item for item in self.history if item['timestamp'] > cutoff_time]

def is_dangerous(text: str) -> bool:
    """Check if text contains dangerous patterns"""
    return any(re.search(pattern, text.lower()) for pattern in BLOCKED_PATTERNS)

def clean_and_fix_sql(raw_sql: str) -> str:
    """Clean and fix SQL with proper handling for different column types"""
    logger.info(f"Raw SQL input: {repr(raw_sql)}")

    # Handle case where LLM returns descriptive text instead of SQL
    if "sql query" in raw_sql.lower() and "uid" in raw_sql.lower():
        id_match = re.search(r"uid[\s_]*(\d+)", raw_sql.lower())
        if id_match:
            uid = id_match.group(1)
            sql = f"SELECT * FROM UserMaster WHERE Uid = {uid}"
            logger.info(f"Extracted UID {uid}, generated SQL: {sql}")
            return sql

    # Extract SQL from code block if present
    match = re.search(r"```sql\s*(.*?)\s*```", raw_sql, re.DOTALL | re.IGNORECASE)
    if match:
        sql = match.group(1).strip()
    else:
        sql = re.sub(r"```", "", raw_sql)
        select_match = re.search(r"(SELECT.*?)(?:\n|$|;)", sql, re.IGNORECASE | re.DOTALL)
        if select_match:
            sql = select_match.group(1).strip()
        else:
            sql = re.sub(r"^(.*?)(SELECT|INSERT|UPDATE|DELETE|WITH)", r"\2", sql, flags=re.IGNORECASE | re.DOTALL)
            sql = sql.strip()

    # If we still don't have a proper SQL query, try to construct one
    if not sql.upper().strip().startswith('SELECT'):
        uid_match = re.search(r"(\d+)", raw_sql)
        if uid_match and ("employee" in raw_sql.lower() or "uid" in raw_sql.lower()):
            uid = uid_match.group(1)
            sql = f"SELECT * FROM UserMaster WHERE Uid = {uid}"
        else:
            return raw_sql

    # Remove sensitive fields from query
    for field in SENSITIVE_FIELDS:
        sql = re.sub(rf'\b{field}\b\s*,?\s*', '', sql, flags=re.IGNORECASE)
        sql = re.sub(rf',\s*\b{field}\b', '', sql, flags=re.IGNORECASE)
        sql = re.sub(rf'\bWHERE\s+\b{field}\b[^A-Z]*?(?=\s+(AND|OR|ORDER|GROUP|LIMIT|$))', 'WHERE ', sql, flags=re.IGNORECASE)
        sql = re.sub(rf'\b(AND|OR)\s+\b{field}\b[^A-Z]*?(?=\s+(AND|OR|ORDER|GROUP|LIMIT|$))', '', sql, flags=re.IGNORECASE)

    # Clean up SQL
    sql = re.sub(r',\s*,', ',', sql)
    sql = re.sub(r'SELECT\s*,', 'SELECT ', sql, flags=re.IGNORECASE)
    sql = re.sub(r',\s*FROM', ' FROM', sql, flags=re.IGNORECASE)
    sql = re.sub(r'WHERE\s+AND', 'WHERE', sql, flags=re.IGNORECASE)
    sql = re.sub(r'WHERE\s+OR', 'WHERE', sql, flags=re.IGNORECASE)
    sql = re.sub(r'WHERE\s*$', '', sql, flags=re.IGNORECASE)

    # Convert exact matches to LIKE for text fields
    text_fields = ['EmpName', 'Contact', 'TcsEmail', 'SbiEmail', 'AdId', 'Position', 'Level', 'Team', 'Project']
    for field in text_fields:
        sql = re.sub(f"({field})\\s*=\\s*'([^']*)'", f"\\1 LIKE '%\\2%'", sql, flags=re.IGNORECASE)

    sql = sql.strip().rstrip(";")

    # Add reasonable limit if none exists
    if not re.search(r"\bLIMIT\b", sql, re.IGNORECASE) and not re.search(r"\bCOUNT\s*\(", sql, re.IGNORECASE):
        sql += " LIMIT 50"

    logger.info(f"Final cleaned SQL: {sql}")
    return sql

def format_query_results_natural(result: List[Dict], question: str) -> str:
    """Format database results in natural language"""
    if not result:
        return "I couldn't find any employee records matching your criteria."

    # Handle single value results (like COUNT)
    if len(result) == 1 and len(result[0]) == 1:
        value = list(result[0].values())[0]
        if "count" in question.lower():
            return f"There are {value} employee records matching your criteria."
        else:
            return f"The result is: {value}"

    # Handle single record
    if len(result) == 1:
        record = result[0]
        response = f"I found 1 employee record:\n\n"

        if 'Uid' in record:
            response += f"🆔 Employee ID: {record['Uid']}\n"
        if 'EmpName' in record:
            response += f"👤 Name: {record['EmpName']}\n"
        if 'Contact' in record:
            response += f"📞 Contact: {record['Contact']}\n"
        if 'TcsEmail' in record:
            response += f"📧 TCS Email: {record['TcsEmail']}\n"
        if 'SbiEmail' in record:
            response += f"📧 SBI Email: {record['SbiEmail']}\n"
        if 'AdId' in record:
            response += f"🔑 AD ID: {record['AdId']}\n"
        if 'Position' in record:
            response += f"💼 Position: {record['Position']}\n"
        if 'Level' in record:
            response += f"📊 Level: {record['Level']}\n"
        if 'Team' in record:
            response += f"👥 Team: {record['Team']}\n"
        if 'Project' in record:
            response += f"📂 Project: {record['Project']}\n"

        return response.strip()

    # Handle multiple records
    response = f"I found {len(result)} employee records matching your criteria:\n\n"

    # Add team summary for multiple results
    if 'Team' in result[0]:
        team_counts = defaultdict(int)
        for record in result:
            team = record.get('Team', 'Unknown')
            team_counts[team] += 1

        response += "📊 Team Summary:\n"
        for team, count in team_counts.items():
            response += f"   • {team}: {count} employees\n"
        response += "\n"

    # Show first few records in detail, then summary for rest
    if len(result) <= 5:
        response += "📋 Detailed Results:\n"
        for i, record in enumerate(result, 1):
            response += f"\n{i}. "
            if 'EmpName' in record:
                response += f"{record['EmpName']} "
            if 'Uid' in record:
                response += f"(ID: {record['Uid']}) "
            if 'Team' in record:
                response += f"- Team: {record['Team']} "
            if 'Position' in record:
                response += f"- Position: {record['Position']}"
    else:
        response += f"📋 Showing summary view (too many records to display individually)\n"
        response += f"Total records: {len(result)}"

    return response

def is_select_query(sql: str) -> bool:
    """Check if query is a safe SELECT query"""
    sql_clean = sql.strip().lower()
    starts_with_select = sql_clean.startswith('select')
    has_dangerous_ops = any(kw in sql_clean for kw in ['insert', 'update', 'delete', 'drop', 'alter', 'create', 'truncate'])
    is_descriptive = any(phrase in sql_clean for phrase in ['this is', 'sql query', 'the query', 'here is'])

    return starts_with_select and not has_dangerous_ops and not is_descriptive

class EnhancedTeamDetailsAssistant:
    def __init__(self):
        self.llm = None
        self.db_handler = None
        self.initialized = False
        self.context = ConversationContext(
            max_items=CONTEXT_CONFIG['max_history_items'],
            expiry_minutes=CONTEXT_CONFIG['context_expiry_minutes']
        )
        self.cache = QueryCache(max_size=CONTEXT_CONFIG['cache_size'])

    def initialize(self):
        """Initialize the Team Details Assistant with optimizations"""
        try:
            # Initialize LLM with optimized settings
            self.llm = OllamaLLM(
                model="myllm:latest",
                temperature=0.1,
                # Add timeout for faster response
                request_timeout=30.0
            )

            # Set up database connection with connection pooling
            db_cfg = TEAM_DB_CONFIG['db_config']
            uri = f"mysql+pymysql://{db_cfg['user']}:{db_cfg['password']}@{db_cfg['host']}/{db_cfg['database']}"

            db_for_llm = SQLDatabase.from_uri(
                uri,
                include_tables=TEAM_DB_CONFIG.get("include_tables"),
                engine_args={
                    "pool_pre_ping": True,
                    "pool_recycle": 1800,  # Recycle connections every 30 minutes
                    "pool_size": 5,
                    "max_overflow": 10,
                    "connect_args": {
                        "connect_timeout": 10,
                        "charset": "utf8mb4"
                    }
                }
            )

            chain = create_sql_query_chain(self.llm, db_for_llm)

            # Create direct connection for executing queries
            db_conn = pymysql.connect(
                host=db_cfg['host'],
                user=db_cfg['user'],
                password=db_cfg['password'],
                database=db_cfg['database'],
                charset='utf8mb4',
                cursorclass=pymysql.cursors.DictCursor,
                autocommit=True,
                connect_timeout=10
            )

            self.db_handler = {
                'chain': chain,
                'connection': db_conn,
                'config': TEAM_DB_CONFIG
            }

            self.initialized = True
            logger.info("Enhanced Team Details Assistant initialized successfully")
            return True

        except Exception as e:
            logger.error(f"Initialization failed: {e}\n{traceback.format_exc()}")
            return False

    def query_team_details(self, question: str, use_context: bool = False) -> Tuple[str, List[Dict]]:
        """Query team details database with context awareness"""
        if not self.db_handler:
            return "❌ Team Details database not available.", []

        try:
            # Check cache first
            cache_key = f"{question}_{use_context}"
            cached_result = self.cache.get(cache_key)
            if cached_result:
                return cached_result, []

            # Clean expired context
            self.context.clear_expired_context()

            # Prepare question with context if needed
            if use_context:
                enhanced_question = self.context.get_relevant_context(question)
                logger.info(f"Using context for question: {question}")
            else:
                enhanced_question = question
                logger.info(f"Processing fresh question: {question}")

            # Preprocess the question to map common terms
            processed_question = enhanced_question.lower()
            for term, field in FIELD_MAPPINGS.items():
                pattern = rf'\b{re.escape(term)}\b'
                processed_question = re.sub(pattern, field, processed_question, flags=re.IGNORECASE)

            # Add database context
            final_question = f"""
{processed_question}

IMPORTANT INSTRUCTIONS:
- Never include or reference these sensitive fields: Pwd, SecQ, SecA
- For phone numbers, use the Contact field
- Use partial matching (LIKE) for name searches
- Focus on non-sensitive employee information: Uid, EmpName, Project, Team, Contact, TcsEmail, Position, Level
- Every time try to find in the entire table data rather than adding limit to query
- try to do case insensitive search .
- when given team details for count,build the query for searching entire table data rather than applying LIMIT
"""

            # Generate SQL query
            start_time = datetime.now()
            raw_sql = self.db_handler['chain'].invoke({"question": final_question})
            generation_time = (datetime.now() - start_time).total_seconds()

            logger.info(f"SQL generation took {generation_time:.2f} seconds")
            logger.info(f"Generated SQL: {raw_sql}")

            # Clean and validate SQL
            sql = clean_and_fix_sql(raw_sql)

            if not is_select_query(sql):
                error_msg = f"❌ Invalid query generated. Only SELECT queries are allowed."
                return error_msg, []

            # Security check for sensitive fields
            for sensitive_field in SENSITIVE_FIELDS:
                if sensitive_field.lower() in sql.lower():
                    logger.warning(f"Blocked query containing sensitive field: {sensitive_field}")
                    return f"🚫 Cannot access sensitive information. Please rephrase your query.", []

            # Execute query
            with self.db_handler['connection'].cursor() as cursor:
                try:
                    execution_start = datetime.now()
                    cursor.execute(sql)
                    result = cursor.fetchall()
                    execution_time = (datetime.now() - execution_start).total_seconds()

                    logger.info(f"Query execution took {execution_time:.2f} seconds, returned {len(result)} rows")

                    # Format response
                    if not result:
                        response = "I couldn't find any employee records matching your criteria.\n\n"
                        response += "💡 Try using broader search terms or check if the data exists."
                    else:
                        response = format_query_results_natural(result, question)

                    # Cache the result
                    self.cache.set(cache_key, response)

                    return response, result

                except pymysql.Error as db_error:
                    error_msg = f"❌ Database Error: {str(db_error)}"
                    logger.error(f"Database error: {db_error}\nSQL: {sql}")
                    return error_msg, []

        except Exception as e:
            error_msg = f"❌ Error processing request: {str(e)}"
            logger.error(f"Query processing error: {e}\n{traceback.format_exc()}")
            return error_msg, []

    def process_question(self, question: str) -> str:
        """Process questions with context awareness"""
        if not self.initialized and not self.initialize():
            return "❌ Team Details Assistant initialization failed."

        if is_dangerous(question):
            return "❌ Question blocked for security reasons."

        # Determine if context should be used
        use_context = self.context.should_use_context(question)

        # Get response
        response, sql_result = self.query_team_details(question, use_context)

        # Extract entities for future context
        entities = self.context.extract_entities(question, sql_result)

        # Add to conversation history
        self.context.add_interaction(question, response, entities)

        return response

    def start_interactive_session(self, query: str) -> str:
        """Process single query with enhanced context awareness"""
        if not self.initialize():
            return "❌ Failed to initialize Enhanced Team Details Assistant."

        try:
            logger.info(f"Processing query: {query}")
            start_time = datetime.now()

            response = self.process_question(query)

            total_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"Total processing time: {total_time:.2f} seconds")

            return response

        except Exception as e:
            error_msg = f"❌ Session error: {str(e)}"
            logger.error(f"Session error: {e}\n{traceback.format_exc()}")
            return error_msg
        finally:
            # Keep connection alive for better performance
            pass

    def get_context_summary(self) -> str:
        """Get current context summary for debugging"""
        if not self.context.history:
            return "No conversation history available."

        summary = f"Context Summary (Last {len(self.context.history)} interactions):\n"
        for i, item in enumerate(self.context.history[-3:], 1):
            summary += f"{i}. Q: {item['question'][:50]}...\n"
            if item['entities']:
                summary += f"   Entities: {item['entities']}\n"

        return summary

def Teammain(query: str) -> str:
    """Enhanced main function with context awareness and performance optimizations"""
    logger.info("🚀 Starting Enhanced Team Details Assistant...")

    # Create or reuse assistant instance (in production, you might want to use a singleton or session-based approach)
    assistant = EnhancedTeamDetailsAssistant()

    result = assistant.start_interactive_session(query)

    logger.info("✅ Query processing complete.")
    return result

# Example usage and testing
if __name__ == "__main__":
    # Test context-aware functionality
    test_queries = [
        "Show me employee with ID 12345",
        "What's his team?",  # Should use context
        "Show me others in the same team",  # Should use context
        "List all employees named John",  # Fresh query
        "What about their projects?",  # Should use context
    ]

    assistant = EnhancedTeamDetailsAssistant()

    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"Query: {query}")
        print(f"Context Decision: {assistant.context.should_use_context(query)}")
        print('='*60)
        result = assistant.start_interactive_session(query)
        print(result)
        print(f"\nContext Summary: {assistant.get_context_summary()}")


